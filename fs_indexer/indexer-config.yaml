# Configuration for the file indexer

# =============================================
# Async Worker Setup Instructions
# =============================================
# To use async checksum calculation:
# 1. Set checksum_mode: "async" in this config
# 2. Start the Redis server and worker process:
#    ./venv/bin/python3 -m fs_indexer.run_checksum_worker
# 3. In another terminal, run the main indexer:
#    ./venv/bin/python3 -m fs_indexer.main
#
# The worker will:
# - Calculate checksums in the background
# - Update the database automatically
# - Handle Redis connection and recovery
# - Process files in batches for efficiency
#
# Monitor the worker logs for progress and any errors
# =============================================

# LucidLink Filespace configuration
lucidlink_filespace:
  enabled: true
  port: 9778  # Port for the LucidLink Filespace API

# =============================================

# Root path to start indexing from (optional, can be provided via --root-path argument)
root_path: "/Volumes/dmpfs/production"

# Database configuration
database:
  connection:
    url: "duckdb:///fs_index.duckdb"
    options:
      memory_limit: "85%"  # Increased memory limit for better performance
      threads: 16  # Match max_workers for better parallelism
      temp_directory: "./.tmp"  # Temporary directory for spilling
      checkpoint_on_shutdown: true  # Ensure data is persisted properly
      compression: "lz4"  # Fast compression algorithm

# Performance tuning
performance:
  # Database settings
  batch_size: 100000  # Return to original batch size
  db_pool_size: 1   # DuckDB only supports 1 writer at a time
  db_max_overflow: 0  # No overflow needed
  read_buffer_size: 268435456  # 256MB for better I/O performance
  max_workers: 16  # Keep number of parallel workers
  
  # Memory settings
  mmap_size: 2147483648  # 2GB for memory-mapped I/O
  
  # File scanning
  scan_chunk_size: 20000  # Process files in chunks during scan
  parallel_scan: true    # Enable parallel directory scanning

  # Query optimization
  enable_parallel_scan: false  # DuckDB doesn't support parallel scans
  vacuum_threshold: 10000  # Run VACUUM after this many updates
  stats_update_frequency: 5000  # Update table statistics after this many changes

# Checksum calculation mode
# - sync: Calculate checksums immediately (slower indexing)
# - async: Queue checksums for background processing (faster indexing)
# - disabled: Skip checksum calculation
checksum_mode: disabled

# Redis configuration for async operations
redis:
  host: localhost
  port: 16379  # Using a non-standard port to avoid conflicts
  db: 0
  # Key prefix for checksum tasks
  checksum_key_prefix: fs_indexer:checksum
  # How long to keep completed checksum tasks (in seconds)
  checksum_ttl: 86400  # 24 hours
  # Worker configuration
  worker:
    batch_size: 100  # Number of files to process in each batch
    retry_interval: 1  # Seconds to wait between retries
    max_retries: 5  # Maximum number of connection retries

# Check and remove database records for files that no longer exist
check_missing_files: false

# Logging configuration
logging:
  level: "INFO"  # Set to DEBUG, INFO, WARNING, ERROR, or CRITICAL
  file: "fs_indexer.log"
  max_size_mb: 10
  backup_count: 5
  console: true  # Also log to console

# Skip patterns for file extensions and specific files
skip_patterns:
  # Skip files with these extensions
  extensions:
    - ".DS_Store"
    - ".git"
    - ".gitignore"
    - ".svn"
    - ".hg"
    - ".idea"
    - "__pycache__"
    - "*.pyc"
    - "*.pyo"
    - "*.pyd"
    - "*.so"
    - "*.dylib"
    - "*.dll"
    - "*.class"
    - "*.o"
    - "*.obj"
  
  # Skip files in these directories
  directories:
    - ".git"
    - ".svn"
    - ".hg"
    - "__pycache__"
    - "node_modules"
    - "venv"
    - ".venv"
    - "env"
    - ".env"
    # - "test_files"
    - "Godzilla_2K"
    - "Godzilla_10K_tif"
    - ".lucid_audit"
    - "test_files/dir_1"
    - "test_files/dir_2"
    - "invalid_dir"  # Test non-existent directory
  
  # Skip hidden files (starting with .)
  skip_hidden: true
